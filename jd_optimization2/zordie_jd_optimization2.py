# -*- coding: utf-8 -*-
"""zordie_jd_optimization2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GBs4A0KqH7suiKQKGpBX3uZzJQneQg_G
"""

# Replace this path with the actual path to your file in Drive
file_path = "/content/drive/MyDrive/jd_optimization_dataset.csv"

# Load the dataset
df = pd.read_csv(file_path)

# Show the first few rows to confirm
df.head()

!pip install -q transformers

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForCausalLM
import torch

# Step 2: Build Prompts from Dataset
def build_prompt(row):
    return f"Improve and expand the following job description:\n\n{row['JD_Before']}"

# Create a new column for prompts
df["Prompt"] = df.apply(build_prompt, axis=1)

# Show a few prompts to verify
df[["Job_Title", "Prompt"]].head()

# Step 3: Load Primary and Fallback Models

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForCausalLM

# Primary: Flan-T5
flan_model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")
flan_tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-base")

# Fallback: Falcon
falcon_model = AutoModelForCausalLM.from_pretrained("tiiuae/falcon-rw-1b")
falcon_tokenizer = AutoTokenizer.from_pretrained("tiiuae/falcon-rw-1b")

# Step 4: Generate Job Descriptions using Flan-T5 with Falcon Fallback
def generate_description(prompt):
    try:
        # Try with Flan-T5
        inputs = flan_tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
        outputs = flan_model.generate(**inputs, max_new_tokens=300)
        return flan_tokenizer.decode(outputs[0], skip_special_tokens=True)
    except Exception as e:
        print(f"Flan-T5 failed: {e}")
        try:
            # Fallback to Falcon
            inputs = falcon_tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
            outputs = falcon_model.generate(**inputs, max_new_tokens=300)
            return falcon_tokenizer.decode(outputs[0], skip_special_tokens=True)
        except Exception as e:
            print(f"Falcon also failed: {e}")
            return "Generation Failed"

# Apply generation on first few rows for now (to test)
df["Generated_JD"] = df["Prompt"].apply(generate_description)

# Show output
df[["Job_Title", "Generated_JD"]].head()

# Step 5: Save the Generated Job Descriptions to a New CSV File

output_path = "/content/drive/MyDrive/final_generated_job_descriptions.csv"
df[["Job_Title", "Generated_JD"]].to_csv(output_path, index=False)

print(f"✅ Final output saved to: {output_path}")

# Final batch generation for all rows using the same function
df["Generated_JD"] = df["Prompt"].apply(generate_description)

# Save full output to a new CSV file
final_output_path = "/content/drive/MyDrive/full_generated_job_descriptions.csv"
df[["Job_Title", "Generated_JD"]].to_csv(final_output_path, index=False)

print(f"✅ Full dataset job descriptions saved to: {final_output_path}")

# Step 6: Template Formatting + Save to CSV

def format_jd(job_title, generated_text):
    formatted = (
        f"Job Title: {job_title}\n\n"
        f"{generated_text.strip()}\n\n"
        f"Apply Now: Interested candidates are encouraged to apply with their updated resume."
    )
    return formatted

# Apply formatting
df["Formatted_JD"] = df.apply(lambda row: format_jd(row["Job_Title"], row["Generated_JD"]), axis=1)

# Save the formatted descriptions to CSV
formatted_output_path = "/content/drive/MyDrive/formatted_generated_job_descriptions.csv"
df[["Job_Title", "Formatted_JD"]].to_csv(formatted_output_path, index=False)

print(f"✅ Formatted job descriptions saved to: {formatted_output_path}")